---
title: "CFMP"
excerpt: "It 's a working paper for crowdfunding project multimodailty reasoning.<br/><img src='/images/cfmp.png'>"
collection: portfolio
---

<!--hi world-->




Would you invest your money in an idea you don't actually see? Can my project be funded and realized? This work may provide some shallow reference both for investors and creators .

The goal of crowdfunding ex-ante prediction is to extract the most relevant information about the project in the context of crowdfunding to form reasoning. Unlike ex-post prediction, the ex-ante prediction does not rely on information obtained after the project is released. However, existing multimodality method fail to represent and align long sequences in the context of crowdfunding effectively, resulting in information noise and decreased prediction performance. To address this issue, we introduce a four-modality fusion method, which can realize modular extraction of multiple modalities to adapt to large-scale modality missing datasets and achieve semantic alignment and fusion in video frame space.

In addition, we propose two large-scale multimodality crowdfunding datasets, ,Kick30 and Kick60, each containing 30,000 and 68,000 crowdfunding projects respectively. The former also includes video frame features extracted by TimeSformer and textual sequence features extracted by BERT. The experiment on Kick30 demonstrate the superiority of our method, achieving state-of-the-art performance in 10/15 of the category. Extensive modality ablation study on both dataset shows the importance of visual and textual information in the reasoning process.

You can find the final report here:[CFMP Research](https://zjzhang1999.github.io/assets/A Four-update github.pdf).




